from langchain import hub
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI

from dotenv import load_dotenv

load_dotenv()

llm = ChatOpenAI(
    model='gpt-4o-mini',
    temperature=0,
)
prompt = hub.pull('rlm/rag-prompt')

generation_chain = prompt | llm | StrOutputParser()